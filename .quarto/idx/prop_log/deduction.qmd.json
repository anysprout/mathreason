{"title":"Deduction","markdown":{"yaml":{"title":"Deduction"},"headingText":"Negation and Disjunction","containsRefs":false,"markdown":"\n\nEntailment is about which propositions \"make\" other propositions \"necessary\". That is to say, if $\\Delta\\vDash \\alpha$ then the truth of $\\Delta$ \"makes\" $\\alpha$ true, so-to-speak. Deduction, on the other hand, is about demonstrating something more like \"reasons why\" the entailment holds.\n\nTake for example the fact that $\\frac{xy}{z}+wx = 1$ for real numbers $w,x,y,z$ with $z\\ne 0$, entails $w=\\frac 1 x - \\frac y z$. It's all good and well that this entailment holds -- but we want a proof! A proof is like receipts, something you can check to validate a claim.\n\n\nHere we will introduce inference rules for negation and disjunction. It will be helpful to have this example in mind:\n\n> Either the enemy will approach by land or by sea. They will not approach by land. Therefore they will approach by sea.\n\nThe clarify of this inference motivates accepting the following as a rule of inference:\n\n> For any propositions $\\alpha$ and $\\beta$, if $\\alpha\\lor\\beta$ and also $\\neg\\beta$ are true, then one may infer $\\alpha$.\n\nWe call the above *Disjunction Elimination*. Every inference rule has some set of **premises**. These are propositions which need to be true in order for the inference rule to apply. In *Disjunction Elimination* the premises are the elements of the set $\\{\\alpha\\lor\\beta,\\neg\\beta\\}$. Every inference rule also has a **conclusion**, which is the sentence that one is licensed to accept by the inference rule. In the case of *Disjunction Elimination* the conclusion is $\\alpha$.\n\nThere is also a rule called *Disjunction Introduction*.\n\n> If $\\alpha$ is true then $\\alpha\\lor\\beta$ is true, for any propositions $\\alpha,\\beta$.\n\nThe premise of *Disjunction Introduction* is $\\{\\alpha\\}$ and the conclusion is $\\alpha\\lor\\beta$.\n\nAn inference rule is called *valid* if the premise entails the conclusion. We will only ever use valid inference rules (which the reader is encouraged to check).[^1]\n\n[^1]: While *Disjunction Elimination* might seem natural, *Disjunction Introduction* might seem strange and unnatural. However, whether it is strange or not, it is still technically *valid*. Moreover, not only is it valid but it will also prove to be useful, so we accept it as one of our inference rules.\n\nTo help express inference rules, we use the following notation.\n\n$$\\begin{aligned}\n\\text{\\it Disjunction Elimination:}&&  \\{\\alpha\\lor\\beta,\\neg\\beta\\} &\\therefore \\alpha\\\\\n\\text{\\it Disjunction Introduction:}&& \\{\\alpha\\} &\\therefore \\alpha\\lor\\beta\n\\end{aligned}\n$$\n\nThe symbol $\\therefore$ is read as \"therefore\", with the premises to its left and the conclusion to its right.\n\nThe disjunction rules are also fairly unwieldy if we have to use them in the rigid order that they appear above. Therefore we will augment the rules to make them easier to use.\n\n$$\\begin{aligned}\n\\text{\\it Disjunction Elimination:}&&  \\{\\alpha\\lor\\beta,\\neg\\beta\\} &\\therefore \\alpha\\\\\n&&\\{\\alpha\\lor\\beta,\\neg\\alpha\\}&\\therefore\\beta\\\\\n\\text{\\it Disjunction Introduction:}&& \\{\\alpha\\} &\\therefore \\alpha\\lor\\beta\\\\\n&&\\{\\alpha\\}&\\therefore \\beta\\lor\\alpha\n\\end{aligned}\n$$\n\nNegation has its own elimination and introduction rules.\n\n$$\\begin{aligned}\n\\text{\\it Negation Elimination:}&& \\neg(\\neg\\alpha)&\\therefore\\alpha\\\\\n\\text{\\it Negation Introduction:}&& \\alpha&\\therefore\\neg(\\neg \\alpha)\n\\end{aligned}$$\n\nAll of these rules will be relatively useless if we don't also accept the reasonable principle that if $\\Delta$ is any set of propositions, and $\\Delta\\subseteq\\Gamma$, then if $\\Delta\\therefore \\alpha$ then also $\\Gamma\\therefore \\alpha$. This is known as the principle of monotonicity. It basically says\n\n> If $\\Delta$ proves $\\alpha$ and if $\\Gamma$ is even more powerful than $\\Delta$, then also $\\Gamma$ proves $\\alpha$.\n\n::: {.callout-important title=\"Exercise Disjunction and Negation\" appearance=\"minimal\"}\nShow that with the premises $\\{\\alpha,\\neg\\alpha\\}$ one can infer $\\alpha\\lor\\beta$ for any proposition $\\beta$.\n\nThen show that $\\{\\alpha,\\neg\\alpha,\\alpha\\lor\\beta\\}\\therefore \\beta$.\n\nNote that it is *not* true that $\\{\\alpha,\\neg\\alpha\\}\\therefore\\beta$.\n:::\n\n# Conjunction, Conditional, Biconditional, and Reiteration\n\nHere are some of the remaining inference rules. You are invited to check any or all of them to be sure that they are valid.\n\n$$\\begin{aligned}\n\\text{\\it Conjunction Elimination:}&& \\{\\alpha\\land\\beta\\}&\\therefore \\alpha\\\\\n&& \\{\\alpha\\land\\beta\\}&\\therefore \\beta\\\\\n\\text{\\it Conjunction Introduction:}&& \\{\\alpha\\}&\\therefore \\alpha\\land\\beta\\\\\n&& \\{\\alpha\\}&\\therefore \\beta\\land\\alpha\\\\\n\\text{\\it Conditional Elimination:}&& \\{\\alpha\\to\\beta,\\alpha\\}&\\therefore \\beta\\\\\n\\text{\\it Biconditional Elimination:}&& \\{\\alpha\\leftrightarrow\\beta,\\alpha\\}&\\therefore \\beta\\\\\n&& \\{\\alpha\\leftrightarrow\\beta,\\beta\\}&\\therefore \\alpha\\\\\n\\text{\\it Reiteration:} && \\alpha &\\therefore \\alpha\n\\end{aligned}$$\n\n::: {.callout-important title=\"Conjunction Exercise\" appearance=\"minimal\"}\nProve that $\\{P,Q,R\\}\\therefore Q\\land R$ and $\\{P,Q,R, Q\\land R\\}\\therefore P\\land(Q\\land R)$.\n:::\n\n# Deduction\n\nWe have seen several inference rules. If we then chain together inference rules, we get what is called a **deduction**.[^2] We have already seen a few examples, like how $\\{\\alpha,\\neg\\alpha\\}\\therefore \\alpha\\lor\\beta$ and then $\\{\\alpha,\\neg\\alpha,\\alpha\\lor\\beta\\}\\therefore\\beta$. We represent chaining these together by putting them in a so-called two-column proof.\n\n[^2]: Also often called a \"derivation\".\n\n$$\n\\definecolor{subtle}{rgb}{.99,.99,.9}\n\\begin{array}{|l|c|c|} \\hline\n\\text{No.}&\\text{ Prop } & \\text{Reason}\\\\\\hline\n1. & \\alpha & \\text{Premise} \\\\ \\rowcolor{subtle}\n2. & \\neg\\alpha & \\text{Premise} \\\\\n3. & \\alpha\\lor\\beta & \\lor\\text{I}, 1\\\\ \\rowcolor{subtle}\n4. & \\beta & \\lor\\text{E},2,3\\\\\\hline\n\\end{array}\n$$\n\nWhat the table represents is that, on lines 1 and 2, we start from some premises. As we proceed to next lines, we can always reference earlier lines in the proof, and apply inference rules to derive new lines. Therefore line 3 is allowed to derive $\\alpha\\lor\\beta$ from line 1, using the *Disjunction Introduction* inference rule. Because propositions merely \"accumulate\" as we go, then by the time we reach line 4, it is allows to use all of the lines before it, to derive a new line. In this particular example, it uses lines 2 and 3 with the inference rule for *Disjunction Elimination*.\n\nIn a two-column proof, every line must contain both a proposition and a \"justification\". That justification can be either (1) premise, for propositions in the premise of the deduction, or (2) any inference rule, applied to lines earlier in the proof.\n\nSince there is a deduction from premise $\\{\\alpha,\\neg\\alpha\\}$ to proposition $\\beta$, we express the existence of this deduction by writing $\\{\\alpha,\\neg\\alpha\\}\\vdash\\beta$. In this case we say that $\\{\\alpha,\\neg\\alpha\\}$ **proves** $\\beta$.\n\n::: {.callout-important title=\"Chaining Exercise\" appearance=\"minimal\"}\nShow that $\\{P,Q,R\\}\\vdash P\\land (Q\\land R)$ and also $\\{P,Q,R\\}\\vdash R\\land(P\\land Q)$.\n:::\n\n::: {.callout-important title=\"Arrow Conjunction Exercise\" appearance=\"minimal\"}\nShow that $\\{(P\\to Q)\\land (P\\to R), P\\}\\vdash Q\\land R$.\n:::\n\n## Conditional Introduction\n\nYou will no doubt have noticed that most operations have an elimination and an introduction rule, but with one conspicuous exception. There is no conditional introduction rule! The reason for this omission is that the conditional introduction rule requires a new technique that we will introduce here.\n\nIt is perhaps easiest to simply give a demonstration. Suppose that we would like to prove $\\{P\\lor Q\\} \\vdash \\neg P\\to Q$. Intuitively, the argument would go like this: \"*Suppose* that $\\neg P$ is true. Well then, we now have $\\{P\\lor Q,\\neg P\\}$ as our premise. In that case we can use *Disjunction Elimination* to infer $Q$. Since the supposition of $\\neg P$ leads to $Q$, we can therefore infer that 'If $\\neg P$ then $Q$.'\"\n\nThis is effectively a \"subproof\". That is to say, we assume $\\neg P$ and then conduct a proof of something (in this example, that \"something\" is $Q$). At the end of the subproof, we then \"export\" a conditional proposition. The conditional has, as its antecedent, whatever we assumed for the subproof. It has as its consequent, whatever the subproof ended with. In the two-column system we would represent the subproof like this:\n\n$$\n\\definecolor{subtl}{rgb}{.95,.95,.85}\n\\begin{array}{|c|c|c|} \\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n1. & P\\lor Q & \\text{Premise} \\\\ \\rowcolor{subtle}\n2. & \\neg P\\to Q & \n\\begin{array}{|c|c|c|} \\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n2.1. & \\neg P & \\text{$\\to$ Assumption} \\\\\\hline \\rowcolor{subtl}\n2.2. & Q & \\lor\\text{E}, 1., 2.1. \\\\\\hline\n\\end{array} \\\\\\hline\n\\end{array}\n$$\n\nNotice that the justification for line 2 is the subproof. Also notice the system that we adopt for numbering lines in a subproof. In the subproof on line number 2, the reason is $\\lor$E, 1, 2.1. What this means is that, of course, line 1 contains $P\\lor Q$. But where is 2.1? It is on line 2 of the main proof, but inside of line 2 we refer to line 1 of the subproof there. This is where we find the proposition $\\neg P$.\n\nAnd indeed, from $P\\lor Q$ and $\\neg P$ we are able to infer, with *Disjunction Elimination*, the proposition $Q$. This is what I have entered at line 2.2.\n\n------------------------------------------------------------------------\n\nHere's another example where I prove that $\\{P\\to Q\\}\\vdash \\{P\\to (R\\lor Q)\\}$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n    \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n    1. & P\\to Q & \\text{Premise} \\\\\\hline \\rowcolor{subtle}\n    2. & P\\to (R\\lor Q) & \n        \\begin{array}{|c|c|c|}\\hline \n        \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n        2.1. & P & \\text{$\\to$Assumption} \\\\ \\rowcolor{subtl} \n        2.2. & Q & \\to\\text{E}, 1., 2.1.\\\\\n        2.3. & R\\lor Q & \\lor\\text{I}, 2.2. \\\\ \\hline\n        \\end{array}\\\\\\hline\n\\end{array}\n$$\n\nAgain notice how this works: We want to prove $P\\to (R\\lor Q)$, so we make a subproof with assumption $P$ and ending at $R\\lor Q$.\n\n------------------------------------------------------------------------\n\nHere's an example of a proof *with no premises*. This is in fact possible because the *Conditional Introduction* does not require there to be any premises -- it allows you to make any assumption that you want, at any time!\n\nWe will prove $\\emptyset\\vdash P\\to P$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline \n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\ \\hline\n1. & P\\to P & \n  \\begin{array}{|c|c|c|}\\hline\n  \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n  1.1. & P & \\to\\text{Assumption} \\\\ \\rowcolor{subtle}\n  1.2. & P & \\text{Reit}, 1.1. \\\\ \\hline\n  \\end{array}\\\\\\hline\n\\end{array}\n$$\n\nThis might seem like a strange argument. What is this \"Reit\"? It is the *Reiteration* rule that was introduced in the long list of various inference rules. It says, effectively, that if a proposition is on any line in a proof, then on a later line we can always choose to \"reiterate\" it on a new line.\n\nThis is pretty much only useful in conditional proofs, where we really *need* the last line of the proof to be our \"target\" consequent of the conditional. In this case we needed it to be $P$, because that is the consequent of the proposition that we're proving, $P\\to P$.\n\n------------------------------------------------------------------------\n\nLet's next see a proof from no premises that $\\emptyset\\vdash (P\\land (P\\to Q))\\to Q$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n\\text{No.}&\\text{Prop}&\\text{Reason}\\\\\\hline\n1. & (P\\land(P\\to Q))\\to Q & \n  \\begin{array}{|c|c|c|}\\hline\n  1.1. & P\\land(P\\to Q)& \\to\\text{Assumption} \\\\ \\rowcolor{subtle}\n  1.2. & P & \\land\\text{E},1.1.\\\\\n  1.3. & P\\to Q & \\land\\text{E},1.1\\\\\\rowcolor{subtle}\n  1.4. & Q & \\to\\text{E},1.2.,1.3. \\\\\n  \\hline\n  \\end{array}\\\\\\hline\n\\end{array}\n$$\n\n### Restrictions on Conditional Proof\n\nI have not yet really specified the rules of conditional proof, because they can be somewhat difficult to understand. For now I have mostly tried to communicate the method by examples. However, take the following example which demonstrates that this technique is invalid if used in the wrong ways.\n\n$$\n\\begin{array}{|c|c|c|} \\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n1. & P\\to (P\\lor Q) & \n  \\begin{array}{|c|c|c|} \\hline\n  1.1. & P & \\text{Assumption} \\\\ \\rowcolor{subtle}\n  1.2. & P\\lor Q & \\lor\\text{I},1.1\\\\\\hline\n  \\end{array} \\\\ \\rowcolor{subtle}\n2. & P & \\text{Reit}, 1.1 \\\\\\hline\n\\end{array}\n$$\n\nNotice that the above argument only uses our inference rules, so it seems like an acceptable proof! Does that mean that our *Conditional Introduction* rule is invalid?\n\nIf it is used \"unrestrictedly\" then yes. Therefore we must place restrictions on it, so that the rule will be valid. The problem with the above proof, is the very last step. On line 2, it justifies writing a proposition ( $P$) based on a line (1.1.) which was only introduced for conditional proof. But lines that occur in a subproof are only meant to be used for the subproof and not outside of it.\n\nSince this is the source of the invalidity, this is precisely the restriction that we place on all proofs: On any line of a proof, one is only allowed to reference lines which do not come from a \"closed\" subproof. So for instance, in the above proof it is fine for like 1.2 to reference 1.1, because at line 1.2 the subproof is not yet closed. But at line 2. it is not acceptable to reference line 1.1 because that occurs in a subproof which, by line 2 has already been closed.\n\n::: {.callout-important title=\"Valid References\" appearance=\"minimal\"}\nConsider the following proof.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n  \\text{No.}&\\text{Prop}&\\text{Reason}\\\\\\hline\n  1. & (P\\land Q) \\to P & \n    \\begin{array}{|c|c|c|}\\hline\n    \\text{No.}&\\text{Prop}&\\text{Reason}\\\\\\hline\n    1.1. & P\\land Q & \\to\\text{Assumption}\\\\\\rowcolor{subtle}\n    1.2. & P & \\land\\text{E} \\\\\\hline\n    \\end{array}\\\\\\hline\\rowcolor{subtle}\n  2. & P & \\to\\text{E}, 1., 1.1. \\\\\\hline\n\\end{array}\n$$\n\nIs this a valid argument? If not, at which line is an invalid inference made?\n:::\n\n## Proof by Contradiction\n\nThere is a second proof method which uses subproofs. This is proof by contradiction. Consider the following argument which illustrates the technique.\n\n> We will prove that there is no largest number. For contradiction, suppose that there is a largest number and call it $x$. Then $x+1$ is a number and larger. Therefore $x$ is both largest (by assumption) and not largest (because there is a larger number). This is a contradiction. Because the assumption that there is a largest number produced a contradiction, then the assumption must be false. So there is no largest number.\n\nThe idea is that we\n\n1.  Assume the *negation* of what you hope to prove. (e.g. \"there *is* a largest number\")\n2.  From the assumption, derive a contradiction. (\"$x$ is largest and not largest\")\n3.  Therefore end the subproof, and infer what you wanted to prove. (\"there is *no* largest number\")\n\nBelow I'll illustrate this technique in a two-column proof that $\\{P\\lor Q\\}\\vdash \\neg(\\neg P\\land\\neg Q)$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n1. & P\\lor Q & \\text{Premise} \\\\ \\rowcolor{subtle}\n2. & \\neg(\\neg P\\land \\neg Q) & \n  \\begin{array}{|c|c|c|}\\hline\n  \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n  2.1. & \\neg(\\neg(\\neg P\\land \\neg Q)) & \\unicode{x21af} \\text{Assumption}\\\\\\rowcolor{subtl}\n  2.2. & \\neg P\\land \\neg Q & \\neg\\text{E},2.1. \\\\\n  2.3. & \\neg P & \\land\\text{E},2.2. \\\\ \\rowcolor{subtl} \n  2.4. & \\neg Q & \\land \\text{E},2.2. \\\\\n  2.5. & Q & \\lor\\text{E},1.,2.4. \\\\ \\rowcolor{subtl}\n  2.6. & Q\\land\\neg Q& \\land\\text{I}, 2.4.,2.5.\\\\\\hline\n\\end{array} \\\\ \\hline\n\\end{array}\n$$\n\nNotice how the subproof in line 2 ends on the contradiction $Q\\land\\neg Q$. Every proof by contradiction must end on a line containing $\\alpha\\land\\neg\\alpha$ or $\\neg\\alpha\\land\\alpha$, for some proposition $\\alpha$.\n\n------------------------------------------------------------------------\n\nHere is a proof that $\\{\\neg(P\\land Q)\\}\\vdash \\neg P\\lor\\neg Q$. This will be somewhat interesting in that it has a subproof within a subproof!\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n\\text{No.}&\\text{Prop}&\\text{Reason} \\\\\\hline\n1. & \\neg(P\\land Q) & \\text{Premise}\\\\ \\rowcolor{subtle}\n2. & \\neg P\\lor\\neg Q & \n  \\begin{array}{|c|c|c|}\\hline\n  \\text{No.}&\\text{Prop}&\\text{Reason} \\\\\\hline\n  2.1 & \\neg(\\neg P\\lor \\neg Q) & \\unicode{x21af}\\text{Assumption}\\\\ \\rowcolor{subtl}\n  2.2. & P & \n    \\begin{array}{|c|c|c|}\\hline\n    \\text{No.}&\\text{Prop}&\\text{Reason} \\\\\\hline\n    2.2.1. & \\neg P & \\unicode{x21af}\\text{Assumption}\\\\\n    2.2.2. & \\neg P\\lor\\neg Q & \\lor\\text{I},2.2.1\\\\\n    2.2.3. & \\begin{array}{c} \\\\\\neg(\\neg P\\lor\\neg Q)\\land \\\\ \\neg P\\lor\\neg Q\\end{array} & \\land\\text I, 2.1, 2.2.3. \\\\\\hline\n    \\end{array}\\\\\n  2.3. & Q & \\text{Similar to above.} \\\\ \\rowcolor{subtl}\n  2.4. & P\\land Q & \\land\\text{I}, 2.2, 2.3 \\\\\n  2.5. & (P\\land Q)\\land \\neg (P\\land Q) & \\land\\text I, 1., 2.4 \\\\\\hline\n  \\end{array}\\\\\\hline\n\\end{array}\n$$\n\n::: {.callout-important title=\"Proof Exercises\" appearance=\"minimal\"}\nProve the following.\n\n1.  $\\{\\neg(P\\to Q) \\}\\vdash P$\n2.  $\\emptyset \\vdash P\\lor\\neg P$\n3.  $\\{P\\land\\neg P\\}\\vdash \\alpha$ for any proposition $\\alpha$\n4.  $\\{P\\lor Q, P\\to R, Q\\to S\\}\\vdash R\\lor S$\n:::\n\n# Deductions in Python\n\nIt is possible to simply give a computer some set of propositions, and a conclusion, and have a program find a deduction from the premise to the conclusion. However, that is quite a challenging task and so we won't try to implement the idea here.\n\nWhat is still challenging, but not THAT challenging, though, is to write a program which checks an argument for validity. For instance we might represent an argument as a list of proposition-inference pairs.\n\n```{python}\nargument = [(\"Premise\",\"P\"), (\"Premise\",\"if P then Q\"), (\"Conditional Elimination,1,2\",\"Q\")]\n```\n\nNaturally a component of what we need, is to decide if something like this is an instance of one of our inference rules. In particular, the easiest case is when it's an instance of an inference rule that does not make use of any subproof.\n\nBelow is a function which can detect if a given list of sentences is an instance of *Disjunction Elimination*. We will assume that there are three elements of the list, which are of the `Proposition` class. This class and related code were developed in a previous section, and are reproduced here. You will need to run this code in order to rule the code that follows it.\n\nNote that the classes need to be extended by an implementation of `__eq__`. If you check the implementation of `disjunction_elimination` you can see that we need to check the equality of various propositions, hence the need for this extension.\n\n```{python}\n### OLD CODE ###\nimport pyparsing as pp\n\nclass Proposition:\n    pass\n\nclass PropVariable(Proposition):\n    def __init__(self, v):\n        assert (type(v) == type(\"\") and len(v) == 1) \n        self.v = v\n    def __str__(self):\n        return(self.v)\n    def eval(self, prop_eval):\n        return prop_eval(self.v)\n    def __eq__(self, p):\n        if type(p) == PropVariable: return p.v == self.v\n        return False\n\nclass Negation(Proposition):\n    def __init__(self, beta):\n        assert issubclass(type(beta),Proposition)\n        self.neg = beta\n    def __str__(self):\n        return(\"(not \" + str(self.neg) + \")\")\n    def eval(self, prop_eval):\n        return(not self.neg.eval(prop_eval))\n    def __eq__(self, p):\n        if type(p) == Negation: return p.neg == self.neg\n        return False\n\nclass Disjunction(Proposition):\n    def __init__(self, beta, gamma):\n        assert issubclass(type(beta),Proposition) \\\n            and issubclass(type(gamma),Proposition)\n        self.left, self.right = beta, gamma\n    def __str__(self):\n        return(\"(\" + str(self.left )+\" or \" + str(self.right) + \")\")\n    def eval(self, prop_eval):\n        l, r = self.left.eval(prop_eval), self.right.eval(prop_eval)\n        return( l or r )\n    def __eq__(self, p): \n        if type(p) == Disjunction: \n            return p.left == self.left and p.right == self.right\n        return False\n\nclass Conditional(Proposition):\n    def __init__(self, beta, gamma):\n        assert issubclass(type(beta),Proposition) \\\n            and issubclass(type(gamma),Proposition)\n        self.ante, self.conseq = beta, gamma\n    def __str__(self):\n        return(\"(if \" + str(self.ante) + \" then \" + str(self.conseq) + \")\")\n    def eval(self, prop_eval):\n        ante, conseq = self.ante.eval(prop_eval), self.conseq.eval(prop_eval)\n        return (not ante) or conseq\n    def __eq__(self, p) -> bool:\n        if type(p) == Conditional:\n            return p.ante==self.ante and p.conseq==self.conseq\n        return False\n\ndef parseTree(p):\n    if type(p) == type(\"\"):\n        return PropVariable(p)\n    if len(p) == 1:\n        return parseTree(p[0])\n    if len(p) == 2:\n        assert( p[0] == \"not\" )\n        return Negation(parseTree(p[1]))\n    \n    if len(p) == 3:\n        if p[1] == \"or\": return Disjunction(parseTree(p[0]), parseTree(p[2]))\n        raise Exception(\"length 3 list but unrecognized middle token\")\n    if len(p) == 4:\n        if p[0] == \"if\" and p[2] == \"then\":\n            return Conditional(parseTree(p[1]),parseTree(p[3]))\n    raise Exception(\"length of list unrecognized\")\n\nterms = pp.Word(pp.alphas) | \"not\" | \"and\" | \"or\" | \"if\" | \"then\" | \"iff\" \nnesting = pp.nestedExpr( '(', ')', content=terms )\n\ndef shape(s): \n    if s.strip() == \"\": return \"\"\n    p = nesting.parseString(\"(\"+s+\")\")[0]\n    \n    return parseTree(p)\n```\n\n```{python}\n### NEW CODE ###\ndef disjunction_elimination(sup1,sup2,conc):\n    # For disjunction elimination, one proposition must be a disjunction\n    # and the other must be a negation.\n    disj, neg = sup1, sup2\n    if type(disj) != Disjunction: \n        disj, neg = sup2, sup1\n    if type(disj) != Disjunction or type(neg) != Negation: \n        return False\n  \n    # In order to reach this line of the function, we must have a disjunction\n    # in `disj` and negation in `neg`.  \n    \n    # Now in order to be an instance of *Disjunction Elimination*, the \n    # propsition under the negation must match one of the two disjuncts.\n    # Whichever disjunct matches, the other disjunct should be the final \n    # proposition in the inference (the conclusion).\n    under = neg.neg\n    other = disj.right\n    if under != disj.left:\n        print(str(disj.left))\n        other = disj.left\n        if under != disj.right: \n            return False\n    return other == conc\n\n# disj = shape(\"P or Q\")\n# neg = shape(\"not P\")\n# conc = shape(\"Q\")\n\n# print(disjunction_elimination(disj,neg,conc))\n```\n\n::: {.callout-important title=\"Other Inference Rules in Python\" appearance=\"minimal\"}\nImplement functions to check the other inference rules that don't require a subproof, like for instance *Disjunction Introduction* and *Conjunction Elimination* and so on. Note that not every rule requires three propositions, but every rule does have some set of premises and some conclusion.\n:::\n\nIt remains then to check an inference based on a subproof. Of course checking a subproof is barely different from checking an entire proof, so we should now write that.\n\nTo check an entire proof, we need to iterate over each pair of reason and proposition. We reference the propositions and the inference rule, put them through one of the inference checkers that we've already made. If every proposition passes the test, the proof is valid!\n\nWe will assume that proofs are formatted in a comma-separated string. The commas will separate triples, which are themselves separated by semi-colons. Each triple will contain the information in a row of a two-column proof: Row number, proposition, and reason. Here is an example, with extra spaces for readability.\n\n```{python}\nargument = \"(1.; P and Q; Premise), (2.; if P then (Q or R); Conditional Proof), (2.1.; P; Assumption), (2.2.; Q or R; Or Introduction, 2.), (2.2.3.; ; End Subproof)\"\n```\n\nThe following code is not terribly interesting -- it mostly handles tedious issues of parsing and structuring the argument string.  \n\n```{python}\n### BORING CODE ###\ndef rows_list(argument):\n    level = 0\n    bucket = []\n    row = \"\"\n    for c in argument:\n        if c == \")\": \n            level -= 1\n            if level == 0:\n                bucket.append(row)\n                row = \"\"\n        if level > 0: row += c\n        if c == \"(\": level += 1\n    return bucket\n```\n\n```{python}\ndef incr_rownum(num, reason_name):\n    if reason_name == \"Assumption\":\n        num += [1]\n    elif reason_name == \"End Subproof\":\n        num = num[:-1]\n        num[-1] += 1\n    else:\n        num[-1] += 1\n```\n\n```{python}\ndef row_string_to_list(rs):\n    bucket = rs.split(\".\")[:-1]\n    for i in range(len(bucket)):\n        bucket[i] = int(bucket[i])\n    return bucket\n```\n\n```{python}\ndef x_sees_y(x, y):\n    n1, n2 = len(y), len(x)\n    if n2 < n1: return False\n    for i in range(n1-1):\n        if y[i] != x[i]: \n            return False\n    return y[n1-1] <= x[n1-1]\n```\n\nHere is where the more interesting part of the code begins, as it implements a lot of the concepts of argument validity.  Note that, if you'd like to see the details, the function above `x_sees_y`, could be interesting too.  It determines, for some two row numbers, whether one is allowed to \"see\" the other.  If `y` is in a subproof closed off from `x`, then it returns `False`.  Also if `y` is further along in the proof than `x`, it returns `False`.  But if `y` is supposed to be accessible from `x`, then it returns `True`.  \n\n```{python}\n### INTERESTING CODE ###\ndef validate(argument):\n    # Preprocess the argument into a list of lists.  \n    rl = rows_list(argument)\n    for i in range(len(rl)):\n        rl[i] = rl[i].split(\"; \")\n        rl[i][0] = row_string_to_list(rl[i][0])\n        rl[i][1] = shape(rl[i][1])\n    # When the preprocessing is done, the input \n    # \"(1.; P or Q; Premise), (2.; R or (P or Q); Disjunction Introduction, 1.)\" \n    # looks like \n    # [[[1], Disjunction(...), \"Premise\"], \\\n    #  [[2], Disjunction(...), \"Disjunction Introduction, 1.\"]]\n\n    # We will validate the row numbering of the argument, by \n    # building our own row numbering as we iterate through the \n    # list, and check that it matches the given numbering.\n    rownum = [1]\n    for i, row in enumerate(rl):\n        \n        if rownum != row[0]:\n            raise Exception(\"Invalid row numbering.\")\n        \n        reason = row[2].split(\", \")\n        reason_name = reason[0]\n        incr_rownum(rownum, reason_name)\n\n        if reason_name in [\"Premise\", \"Assumption\", \"End Subproof\"]: \n            continue\n\n        # Validating *Disjunction Elimination* requires \n        if reason_name == \"Disjunction Elimination\":\n            # finding the referenced row numbers\n            sup_ind1 = row_string_to_list(reason[1]) \n            sup_ind2 = row_string_to_list(reason[2])\n\n            # checking that they're not in a closed \n            # subproof\n            if not (x_sees_y(row[0],sup_ind1) and \\\n                    x_sees_y(row[0],sup_ind2)):\n                return False\n            \n            # getting the row at these numbers\n            for r in rl:\n                if r[0] == sup_ind1:\n                    sup1 = r[1]\n                if r[0] == sup_ind2:\n                    sup2 = r[1]\n            \n            # and checking that they match the pattern.\n            if not disjunction_elimination(sup1,sup2,row[1]):\n                return False\n        \n        if reason_name == \"Conditional Introduction\":\n            cond_prop = row[1]\n            next_row = rl[i+1]\n            if type(cond_prop) != Conditional:\n                return False\n            # Conditional introduction checks the next row to see\n            # that it's the beginning of an assumption with the \n            # same proposition as is the antecedent of the \n            # conditional.\n            cert = next_row[2] == \"Assumption\"\n            cert *= cond_prop.ante == next_row[1]\n            if not cert: return False\n            # Then it finds the closing \"End Subproof\", and checks\n            # that on the line before, the subproof ended at the \n            # consequent of the conditional.\n            cert = False\n            for j in range(i+1,len(rl)):\n                if len(rl[j][0]) == len(next_row[0]) \\\n                    and rl[j][2] == \"End Subproof\" \\\n                    and rl[j-1][1] == row[1].conseq:\n                    cert = True\n            if not cert: return cert\n        \n        return True\n\n        \n# disj_argument = \"(1.; P or Q; Premise), (2.; not Q; Premise), (3.; P; Disjunction Elimination, 1., 2.)\"\n# print(validate(disj_argument))\n\n# cond_argument = \"(1.; if P then Q; Conditional Introduction), (1.1.; P; Assumption), (1.2.; Q; Premise), (1.3.; ; End Subproof))\"\n# print(validate(cond_argument))\n        \n\n```\n\n::: {.callout-important title=\"Full Proof Assistant\" appearance=\"minimal\"}\nImplement the remaining inference rules and use them to extend the proof checker.\n:::","srcMarkdownNoYaml":"\n\nEntailment is about which propositions \"make\" other propositions \"necessary\". That is to say, if $\\Delta\\vDash \\alpha$ then the truth of $\\Delta$ \"makes\" $\\alpha$ true, so-to-speak. Deduction, on the other hand, is about demonstrating something more like \"reasons why\" the entailment holds.\n\nTake for example the fact that $\\frac{xy}{z}+wx = 1$ for real numbers $w,x,y,z$ with $z\\ne 0$, entails $w=\\frac 1 x - \\frac y z$. It's all good and well that this entailment holds -- but we want a proof! A proof is like receipts, something you can check to validate a claim.\n\n# Negation and Disjunction\n\nHere we will introduce inference rules for negation and disjunction. It will be helpful to have this example in mind:\n\n> Either the enemy will approach by land or by sea. They will not approach by land. Therefore they will approach by sea.\n\nThe clarify of this inference motivates accepting the following as a rule of inference:\n\n> For any propositions $\\alpha$ and $\\beta$, if $\\alpha\\lor\\beta$ and also $\\neg\\beta$ are true, then one may infer $\\alpha$.\n\nWe call the above *Disjunction Elimination*. Every inference rule has some set of **premises**. These are propositions which need to be true in order for the inference rule to apply. In *Disjunction Elimination* the premises are the elements of the set $\\{\\alpha\\lor\\beta,\\neg\\beta\\}$. Every inference rule also has a **conclusion**, which is the sentence that one is licensed to accept by the inference rule. In the case of *Disjunction Elimination* the conclusion is $\\alpha$.\n\nThere is also a rule called *Disjunction Introduction*.\n\n> If $\\alpha$ is true then $\\alpha\\lor\\beta$ is true, for any propositions $\\alpha,\\beta$.\n\nThe premise of *Disjunction Introduction* is $\\{\\alpha\\}$ and the conclusion is $\\alpha\\lor\\beta$.\n\nAn inference rule is called *valid* if the premise entails the conclusion. We will only ever use valid inference rules (which the reader is encouraged to check).[^1]\n\n[^1]: While *Disjunction Elimination* might seem natural, *Disjunction Introduction* might seem strange and unnatural. However, whether it is strange or not, it is still technically *valid*. Moreover, not only is it valid but it will also prove to be useful, so we accept it as one of our inference rules.\n\nTo help express inference rules, we use the following notation.\n\n$$\\begin{aligned}\n\\text{\\it Disjunction Elimination:}&&  \\{\\alpha\\lor\\beta,\\neg\\beta\\} &\\therefore \\alpha\\\\\n\\text{\\it Disjunction Introduction:}&& \\{\\alpha\\} &\\therefore \\alpha\\lor\\beta\n\\end{aligned}\n$$\n\nThe symbol $\\therefore$ is read as \"therefore\", with the premises to its left and the conclusion to its right.\n\nThe disjunction rules are also fairly unwieldy if we have to use them in the rigid order that they appear above. Therefore we will augment the rules to make them easier to use.\n\n$$\\begin{aligned}\n\\text{\\it Disjunction Elimination:}&&  \\{\\alpha\\lor\\beta,\\neg\\beta\\} &\\therefore \\alpha\\\\\n&&\\{\\alpha\\lor\\beta,\\neg\\alpha\\}&\\therefore\\beta\\\\\n\\text{\\it Disjunction Introduction:}&& \\{\\alpha\\} &\\therefore \\alpha\\lor\\beta\\\\\n&&\\{\\alpha\\}&\\therefore \\beta\\lor\\alpha\n\\end{aligned}\n$$\n\nNegation has its own elimination and introduction rules.\n\n$$\\begin{aligned}\n\\text{\\it Negation Elimination:}&& \\neg(\\neg\\alpha)&\\therefore\\alpha\\\\\n\\text{\\it Negation Introduction:}&& \\alpha&\\therefore\\neg(\\neg \\alpha)\n\\end{aligned}$$\n\nAll of these rules will be relatively useless if we don't also accept the reasonable principle that if $\\Delta$ is any set of propositions, and $\\Delta\\subseteq\\Gamma$, then if $\\Delta\\therefore \\alpha$ then also $\\Gamma\\therefore \\alpha$. This is known as the principle of monotonicity. It basically says\n\n> If $\\Delta$ proves $\\alpha$ and if $\\Gamma$ is even more powerful than $\\Delta$, then also $\\Gamma$ proves $\\alpha$.\n\n::: {.callout-important title=\"Exercise Disjunction and Negation\" appearance=\"minimal\"}\nShow that with the premises $\\{\\alpha,\\neg\\alpha\\}$ one can infer $\\alpha\\lor\\beta$ for any proposition $\\beta$.\n\nThen show that $\\{\\alpha,\\neg\\alpha,\\alpha\\lor\\beta\\}\\therefore \\beta$.\n\nNote that it is *not* true that $\\{\\alpha,\\neg\\alpha\\}\\therefore\\beta$.\n:::\n\n# Conjunction, Conditional, Biconditional, and Reiteration\n\nHere are some of the remaining inference rules. You are invited to check any or all of them to be sure that they are valid.\n\n$$\\begin{aligned}\n\\text{\\it Conjunction Elimination:}&& \\{\\alpha\\land\\beta\\}&\\therefore \\alpha\\\\\n&& \\{\\alpha\\land\\beta\\}&\\therefore \\beta\\\\\n\\text{\\it Conjunction Introduction:}&& \\{\\alpha\\}&\\therefore \\alpha\\land\\beta\\\\\n&& \\{\\alpha\\}&\\therefore \\beta\\land\\alpha\\\\\n\\text{\\it Conditional Elimination:}&& \\{\\alpha\\to\\beta,\\alpha\\}&\\therefore \\beta\\\\\n\\text{\\it Biconditional Elimination:}&& \\{\\alpha\\leftrightarrow\\beta,\\alpha\\}&\\therefore \\beta\\\\\n&& \\{\\alpha\\leftrightarrow\\beta,\\beta\\}&\\therefore \\alpha\\\\\n\\text{\\it Reiteration:} && \\alpha &\\therefore \\alpha\n\\end{aligned}$$\n\n::: {.callout-important title=\"Conjunction Exercise\" appearance=\"minimal\"}\nProve that $\\{P,Q,R\\}\\therefore Q\\land R$ and $\\{P,Q,R, Q\\land R\\}\\therefore P\\land(Q\\land R)$.\n:::\n\n# Deduction\n\nWe have seen several inference rules. If we then chain together inference rules, we get what is called a **deduction**.[^2] We have already seen a few examples, like how $\\{\\alpha,\\neg\\alpha\\}\\therefore \\alpha\\lor\\beta$ and then $\\{\\alpha,\\neg\\alpha,\\alpha\\lor\\beta\\}\\therefore\\beta$. We represent chaining these together by putting them in a so-called two-column proof.\n\n[^2]: Also often called a \"derivation\".\n\n$$\n\\definecolor{subtle}{rgb}{.99,.99,.9}\n\\begin{array}{|l|c|c|} \\hline\n\\text{No.}&\\text{ Prop } & \\text{Reason}\\\\\\hline\n1. & \\alpha & \\text{Premise} \\\\ \\rowcolor{subtle}\n2. & \\neg\\alpha & \\text{Premise} \\\\\n3. & \\alpha\\lor\\beta & \\lor\\text{I}, 1\\\\ \\rowcolor{subtle}\n4. & \\beta & \\lor\\text{E},2,3\\\\\\hline\n\\end{array}\n$$\n\nWhat the table represents is that, on lines 1 and 2, we start from some premises. As we proceed to next lines, we can always reference earlier lines in the proof, and apply inference rules to derive new lines. Therefore line 3 is allowed to derive $\\alpha\\lor\\beta$ from line 1, using the *Disjunction Introduction* inference rule. Because propositions merely \"accumulate\" as we go, then by the time we reach line 4, it is allows to use all of the lines before it, to derive a new line. In this particular example, it uses lines 2 and 3 with the inference rule for *Disjunction Elimination*.\n\nIn a two-column proof, every line must contain both a proposition and a \"justification\". That justification can be either (1) premise, for propositions in the premise of the deduction, or (2) any inference rule, applied to lines earlier in the proof.\n\nSince there is a deduction from premise $\\{\\alpha,\\neg\\alpha\\}$ to proposition $\\beta$, we express the existence of this deduction by writing $\\{\\alpha,\\neg\\alpha\\}\\vdash\\beta$. In this case we say that $\\{\\alpha,\\neg\\alpha\\}$ **proves** $\\beta$.\n\n::: {.callout-important title=\"Chaining Exercise\" appearance=\"minimal\"}\nShow that $\\{P,Q,R\\}\\vdash P\\land (Q\\land R)$ and also $\\{P,Q,R\\}\\vdash R\\land(P\\land Q)$.\n:::\n\n::: {.callout-important title=\"Arrow Conjunction Exercise\" appearance=\"minimal\"}\nShow that $\\{(P\\to Q)\\land (P\\to R), P\\}\\vdash Q\\land R$.\n:::\n\n## Conditional Introduction\n\nYou will no doubt have noticed that most operations have an elimination and an introduction rule, but with one conspicuous exception. There is no conditional introduction rule! The reason for this omission is that the conditional introduction rule requires a new technique that we will introduce here.\n\nIt is perhaps easiest to simply give a demonstration. Suppose that we would like to prove $\\{P\\lor Q\\} \\vdash \\neg P\\to Q$. Intuitively, the argument would go like this: \"*Suppose* that $\\neg P$ is true. Well then, we now have $\\{P\\lor Q,\\neg P\\}$ as our premise. In that case we can use *Disjunction Elimination* to infer $Q$. Since the supposition of $\\neg P$ leads to $Q$, we can therefore infer that 'If $\\neg P$ then $Q$.'\"\n\nThis is effectively a \"subproof\". That is to say, we assume $\\neg P$ and then conduct a proof of something (in this example, that \"something\" is $Q$). At the end of the subproof, we then \"export\" a conditional proposition. The conditional has, as its antecedent, whatever we assumed for the subproof. It has as its consequent, whatever the subproof ended with. In the two-column system we would represent the subproof like this:\n\n$$\n\\definecolor{subtl}{rgb}{.95,.95,.85}\n\\begin{array}{|c|c|c|} \\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n1. & P\\lor Q & \\text{Premise} \\\\ \\rowcolor{subtle}\n2. & \\neg P\\to Q & \n\\begin{array}{|c|c|c|} \\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n2.1. & \\neg P & \\text{$\\to$ Assumption} \\\\\\hline \\rowcolor{subtl}\n2.2. & Q & \\lor\\text{E}, 1., 2.1. \\\\\\hline\n\\end{array} \\\\\\hline\n\\end{array}\n$$\n\nNotice that the justification for line 2 is the subproof. Also notice the system that we adopt for numbering lines in a subproof. In the subproof on line number 2, the reason is $\\lor$E, 1, 2.1. What this means is that, of course, line 1 contains $P\\lor Q$. But where is 2.1? It is on line 2 of the main proof, but inside of line 2 we refer to line 1 of the subproof there. This is where we find the proposition $\\neg P$.\n\nAnd indeed, from $P\\lor Q$ and $\\neg P$ we are able to infer, with *Disjunction Elimination*, the proposition $Q$. This is what I have entered at line 2.2.\n\n------------------------------------------------------------------------\n\nHere's another example where I prove that $\\{P\\to Q\\}\\vdash \\{P\\to (R\\lor Q)\\}$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n    \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n    1. & P\\to Q & \\text{Premise} \\\\\\hline \\rowcolor{subtle}\n    2. & P\\to (R\\lor Q) & \n        \\begin{array}{|c|c|c|}\\hline \n        \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n        2.1. & P & \\text{$\\to$Assumption} \\\\ \\rowcolor{subtl} \n        2.2. & Q & \\to\\text{E}, 1., 2.1.\\\\\n        2.3. & R\\lor Q & \\lor\\text{I}, 2.2. \\\\ \\hline\n        \\end{array}\\\\\\hline\n\\end{array}\n$$\n\nAgain notice how this works: We want to prove $P\\to (R\\lor Q)$, so we make a subproof with assumption $P$ and ending at $R\\lor Q$.\n\n------------------------------------------------------------------------\n\nHere's an example of a proof *with no premises*. This is in fact possible because the *Conditional Introduction* does not require there to be any premises -- it allows you to make any assumption that you want, at any time!\n\nWe will prove $\\emptyset\\vdash P\\to P$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline \n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\ \\hline\n1. & P\\to P & \n  \\begin{array}{|c|c|c|}\\hline\n  \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n  1.1. & P & \\to\\text{Assumption} \\\\ \\rowcolor{subtle}\n  1.2. & P & \\text{Reit}, 1.1. \\\\ \\hline\n  \\end{array}\\\\\\hline\n\\end{array}\n$$\n\nThis might seem like a strange argument. What is this \"Reit\"? It is the *Reiteration* rule that was introduced in the long list of various inference rules. It says, effectively, that if a proposition is on any line in a proof, then on a later line we can always choose to \"reiterate\" it on a new line.\n\nThis is pretty much only useful in conditional proofs, where we really *need* the last line of the proof to be our \"target\" consequent of the conditional. In this case we needed it to be $P$, because that is the consequent of the proposition that we're proving, $P\\to P$.\n\n------------------------------------------------------------------------\n\nLet's next see a proof from no premises that $\\emptyset\\vdash (P\\land (P\\to Q))\\to Q$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n\\text{No.}&\\text{Prop}&\\text{Reason}\\\\\\hline\n1. & (P\\land(P\\to Q))\\to Q & \n  \\begin{array}{|c|c|c|}\\hline\n  1.1. & P\\land(P\\to Q)& \\to\\text{Assumption} \\\\ \\rowcolor{subtle}\n  1.2. & P & \\land\\text{E},1.1.\\\\\n  1.3. & P\\to Q & \\land\\text{E},1.1\\\\\\rowcolor{subtle}\n  1.4. & Q & \\to\\text{E},1.2.,1.3. \\\\\n  \\hline\n  \\end{array}\\\\\\hline\n\\end{array}\n$$\n\n### Restrictions on Conditional Proof\n\nI have not yet really specified the rules of conditional proof, because they can be somewhat difficult to understand. For now I have mostly tried to communicate the method by examples. However, take the following example which demonstrates that this technique is invalid if used in the wrong ways.\n\n$$\n\\begin{array}{|c|c|c|} \\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n1. & P\\to (P\\lor Q) & \n  \\begin{array}{|c|c|c|} \\hline\n  1.1. & P & \\text{Assumption} \\\\ \\rowcolor{subtle}\n  1.2. & P\\lor Q & \\lor\\text{I},1.1\\\\\\hline\n  \\end{array} \\\\ \\rowcolor{subtle}\n2. & P & \\text{Reit}, 1.1 \\\\\\hline\n\\end{array}\n$$\n\nNotice that the above argument only uses our inference rules, so it seems like an acceptable proof! Does that mean that our *Conditional Introduction* rule is invalid?\n\nIf it is used \"unrestrictedly\" then yes. Therefore we must place restrictions on it, so that the rule will be valid. The problem with the above proof, is the very last step. On line 2, it justifies writing a proposition ( $P$) based on a line (1.1.) which was only introduced for conditional proof. But lines that occur in a subproof are only meant to be used for the subproof and not outside of it.\n\nSince this is the source of the invalidity, this is precisely the restriction that we place on all proofs: On any line of a proof, one is only allowed to reference lines which do not come from a \"closed\" subproof. So for instance, in the above proof it is fine for like 1.2 to reference 1.1, because at line 1.2 the subproof is not yet closed. But at line 2. it is not acceptable to reference line 1.1 because that occurs in a subproof which, by line 2 has already been closed.\n\n::: {.callout-important title=\"Valid References\" appearance=\"minimal\"}\nConsider the following proof.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n  \\text{No.}&\\text{Prop}&\\text{Reason}\\\\\\hline\n  1. & (P\\land Q) \\to P & \n    \\begin{array}{|c|c|c|}\\hline\n    \\text{No.}&\\text{Prop}&\\text{Reason}\\\\\\hline\n    1.1. & P\\land Q & \\to\\text{Assumption}\\\\\\rowcolor{subtle}\n    1.2. & P & \\land\\text{E} \\\\\\hline\n    \\end{array}\\\\\\hline\\rowcolor{subtle}\n  2. & P & \\to\\text{E}, 1., 1.1. \\\\\\hline\n\\end{array}\n$$\n\nIs this a valid argument? If not, at which line is an invalid inference made?\n:::\n\n## Proof by Contradiction\n\nThere is a second proof method which uses subproofs. This is proof by contradiction. Consider the following argument which illustrates the technique.\n\n> We will prove that there is no largest number. For contradiction, suppose that there is a largest number and call it $x$. Then $x+1$ is a number and larger. Therefore $x$ is both largest (by assumption) and not largest (because there is a larger number). This is a contradiction. Because the assumption that there is a largest number produced a contradiction, then the assumption must be false. So there is no largest number.\n\nThe idea is that we\n\n1.  Assume the *negation* of what you hope to prove. (e.g. \"there *is* a largest number\")\n2.  From the assumption, derive a contradiction. (\"$x$ is largest and not largest\")\n3.  Therefore end the subproof, and infer what you wanted to prove. (\"there is *no* largest number\")\n\nBelow I'll illustrate this technique in a two-column proof that $\\{P\\lor Q\\}\\vdash \\neg(\\neg P\\land\\neg Q)$.\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n\\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n1. & P\\lor Q & \\text{Premise} \\\\ \\rowcolor{subtle}\n2. & \\neg(\\neg P\\land \\neg Q) & \n  \\begin{array}{|c|c|c|}\\hline\n  \\text{No.} & \\text{Prop} & \\text{Reason} \\\\\\hline\n  2.1. & \\neg(\\neg(\\neg P\\land \\neg Q)) & \\unicode{x21af} \\text{Assumption}\\\\\\rowcolor{subtl}\n  2.2. & \\neg P\\land \\neg Q & \\neg\\text{E},2.1. \\\\\n  2.3. & \\neg P & \\land\\text{E},2.2. \\\\ \\rowcolor{subtl} \n  2.4. & \\neg Q & \\land \\text{E},2.2. \\\\\n  2.5. & Q & \\lor\\text{E},1.,2.4. \\\\ \\rowcolor{subtl}\n  2.6. & Q\\land\\neg Q& \\land\\text{I}, 2.4.,2.5.\\\\\\hline\n\\end{array} \\\\ \\hline\n\\end{array}\n$$\n\nNotice how the subproof in line 2 ends on the contradiction $Q\\land\\neg Q$. Every proof by contradiction must end on a line containing $\\alpha\\land\\neg\\alpha$ or $\\neg\\alpha\\land\\alpha$, for some proposition $\\alpha$.\n\n------------------------------------------------------------------------\n\nHere is a proof that $\\{\\neg(P\\land Q)\\}\\vdash \\neg P\\lor\\neg Q$. This will be somewhat interesting in that it has a subproof within a subproof!\n\n$$\n\\begin{array}{|c|c|c|}\\hline\n\\text{No.}&\\text{Prop}&\\text{Reason} \\\\\\hline\n1. & \\neg(P\\land Q) & \\text{Premise}\\\\ \\rowcolor{subtle}\n2. & \\neg P\\lor\\neg Q & \n  \\begin{array}{|c|c|c|}\\hline\n  \\text{No.}&\\text{Prop}&\\text{Reason} \\\\\\hline\n  2.1 & \\neg(\\neg P\\lor \\neg Q) & \\unicode{x21af}\\text{Assumption}\\\\ \\rowcolor{subtl}\n  2.2. & P & \n    \\begin{array}{|c|c|c|}\\hline\n    \\text{No.}&\\text{Prop}&\\text{Reason} \\\\\\hline\n    2.2.1. & \\neg P & \\unicode{x21af}\\text{Assumption}\\\\\n    2.2.2. & \\neg P\\lor\\neg Q & \\lor\\text{I},2.2.1\\\\\n    2.2.3. & \\begin{array}{c} \\\\\\neg(\\neg P\\lor\\neg Q)\\land \\\\ \\neg P\\lor\\neg Q\\end{array} & \\land\\text I, 2.1, 2.2.3. \\\\\\hline\n    \\end{array}\\\\\n  2.3. & Q & \\text{Similar to above.} \\\\ \\rowcolor{subtl}\n  2.4. & P\\land Q & \\land\\text{I}, 2.2, 2.3 \\\\\n  2.5. & (P\\land Q)\\land \\neg (P\\land Q) & \\land\\text I, 1., 2.4 \\\\\\hline\n  \\end{array}\\\\\\hline\n\\end{array}\n$$\n\n::: {.callout-important title=\"Proof Exercises\" appearance=\"minimal\"}\nProve the following.\n\n1.  $\\{\\neg(P\\to Q) \\}\\vdash P$\n2.  $\\emptyset \\vdash P\\lor\\neg P$\n3.  $\\{P\\land\\neg P\\}\\vdash \\alpha$ for any proposition $\\alpha$\n4.  $\\{P\\lor Q, P\\to R, Q\\to S\\}\\vdash R\\lor S$\n:::\n\n# Deductions in Python\n\nIt is possible to simply give a computer some set of propositions, and a conclusion, and have a program find a deduction from the premise to the conclusion. However, that is quite a challenging task and so we won't try to implement the idea here.\n\nWhat is still challenging, but not THAT challenging, though, is to write a program which checks an argument for validity. For instance we might represent an argument as a list of proposition-inference pairs.\n\n```{python}\nargument = [(\"Premise\",\"P\"), (\"Premise\",\"if P then Q\"), (\"Conditional Elimination,1,2\",\"Q\")]\n```\n\nNaturally a component of what we need, is to decide if something like this is an instance of one of our inference rules. In particular, the easiest case is when it's an instance of an inference rule that does not make use of any subproof.\n\nBelow is a function which can detect if a given list of sentences is an instance of *Disjunction Elimination*. We will assume that there are three elements of the list, which are of the `Proposition` class. This class and related code were developed in a previous section, and are reproduced here. You will need to run this code in order to rule the code that follows it.\n\nNote that the classes need to be extended by an implementation of `__eq__`. If you check the implementation of `disjunction_elimination` you can see that we need to check the equality of various propositions, hence the need for this extension.\n\n```{python}\n### OLD CODE ###\nimport pyparsing as pp\n\nclass Proposition:\n    pass\n\nclass PropVariable(Proposition):\n    def __init__(self, v):\n        assert (type(v) == type(\"\") and len(v) == 1) \n        self.v = v\n    def __str__(self):\n        return(self.v)\n    def eval(self, prop_eval):\n        return prop_eval(self.v)\n    def __eq__(self, p):\n        if type(p) == PropVariable: return p.v == self.v\n        return False\n\nclass Negation(Proposition):\n    def __init__(self, beta):\n        assert issubclass(type(beta),Proposition)\n        self.neg = beta\n    def __str__(self):\n        return(\"(not \" + str(self.neg) + \")\")\n    def eval(self, prop_eval):\n        return(not self.neg.eval(prop_eval))\n    def __eq__(self, p):\n        if type(p) == Negation: return p.neg == self.neg\n        return False\n\nclass Disjunction(Proposition):\n    def __init__(self, beta, gamma):\n        assert issubclass(type(beta),Proposition) \\\n            and issubclass(type(gamma),Proposition)\n        self.left, self.right = beta, gamma\n    def __str__(self):\n        return(\"(\" + str(self.left )+\" or \" + str(self.right) + \")\")\n    def eval(self, prop_eval):\n        l, r = self.left.eval(prop_eval), self.right.eval(prop_eval)\n        return( l or r )\n    def __eq__(self, p): \n        if type(p) == Disjunction: \n            return p.left == self.left and p.right == self.right\n        return False\n\nclass Conditional(Proposition):\n    def __init__(self, beta, gamma):\n        assert issubclass(type(beta),Proposition) \\\n            and issubclass(type(gamma),Proposition)\n        self.ante, self.conseq = beta, gamma\n    def __str__(self):\n        return(\"(if \" + str(self.ante) + \" then \" + str(self.conseq) + \")\")\n    def eval(self, prop_eval):\n        ante, conseq = self.ante.eval(prop_eval), self.conseq.eval(prop_eval)\n        return (not ante) or conseq\n    def __eq__(self, p) -> bool:\n        if type(p) == Conditional:\n            return p.ante==self.ante and p.conseq==self.conseq\n        return False\n\ndef parseTree(p):\n    if type(p) == type(\"\"):\n        return PropVariable(p)\n    if len(p) == 1:\n        return parseTree(p[0])\n    if len(p) == 2:\n        assert( p[0] == \"not\" )\n        return Negation(parseTree(p[1]))\n    \n    if len(p) == 3:\n        if p[1] == \"or\": return Disjunction(parseTree(p[0]), parseTree(p[2]))\n        raise Exception(\"length 3 list but unrecognized middle token\")\n    if len(p) == 4:\n        if p[0] == \"if\" and p[2] == \"then\":\n            return Conditional(parseTree(p[1]),parseTree(p[3]))\n    raise Exception(\"length of list unrecognized\")\n\nterms = pp.Word(pp.alphas) | \"not\" | \"and\" | \"or\" | \"if\" | \"then\" | \"iff\" \nnesting = pp.nestedExpr( '(', ')', content=terms )\n\ndef shape(s): \n    if s.strip() == \"\": return \"\"\n    p = nesting.parseString(\"(\"+s+\")\")[0]\n    \n    return parseTree(p)\n```\n\n```{python}\n### NEW CODE ###\ndef disjunction_elimination(sup1,sup2,conc):\n    # For disjunction elimination, one proposition must be a disjunction\n    # and the other must be a negation.\n    disj, neg = sup1, sup2\n    if type(disj) != Disjunction: \n        disj, neg = sup2, sup1\n    if type(disj) != Disjunction or type(neg) != Negation: \n        return False\n  \n    # In order to reach this line of the function, we must have a disjunction\n    # in `disj` and negation in `neg`.  \n    \n    # Now in order to be an instance of *Disjunction Elimination*, the \n    # propsition under the negation must match one of the two disjuncts.\n    # Whichever disjunct matches, the other disjunct should be the final \n    # proposition in the inference (the conclusion).\n    under = neg.neg\n    other = disj.right\n    if under != disj.left:\n        print(str(disj.left))\n        other = disj.left\n        if under != disj.right: \n            return False\n    return other == conc\n\n# disj = shape(\"P or Q\")\n# neg = shape(\"not P\")\n# conc = shape(\"Q\")\n\n# print(disjunction_elimination(disj,neg,conc))\n```\n\n::: {.callout-important title=\"Other Inference Rules in Python\" appearance=\"minimal\"}\nImplement functions to check the other inference rules that don't require a subproof, like for instance *Disjunction Introduction* and *Conjunction Elimination* and so on. Note that not every rule requires three propositions, but every rule does have some set of premises and some conclusion.\n:::\n\nIt remains then to check an inference based on a subproof. Of course checking a subproof is barely different from checking an entire proof, so we should now write that.\n\nTo check an entire proof, we need to iterate over each pair of reason and proposition. We reference the propositions and the inference rule, put them through one of the inference checkers that we've already made. If every proposition passes the test, the proof is valid!\n\nWe will assume that proofs are formatted in a comma-separated string. The commas will separate triples, which are themselves separated by semi-colons. Each triple will contain the information in a row of a two-column proof: Row number, proposition, and reason. Here is an example, with extra spaces for readability.\n\n```{python}\nargument = \"(1.; P and Q; Premise), (2.; if P then (Q or R); Conditional Proof), (2.1.; P; Assumption), (2.2.; Q or R; Or Introduction, 2.), (2.2.3.; ; End Subproof)\"\n```\n\nThe following code is not terribly interesting -- it mostly handles tedious issues of parsing and structuring the argument string.  \n\n```{python}\n### BORING CODE ###\ndef rows_list(argument):\n    level = 0\n    bucket = []\n    row = \"\"\n    for c in argument:\n        if c == \")\": \n            level -= 1\n            if level == 0:\n                bucket.append(row)\n                row = \"\"\n        if level > 0: row += c\n        if c == \"(\": level += 1\n    return bucket\n```\n\n```{python}\ndef incr_rownum(num, reason_name):\n    if reason_name == \"Assumption\":\n        num += [1]\n    elif reason_name == \"End Subproof\":\n        num = num[:-1]\n        num[-1] += 1\n    else:\n        num[-1] += 1\n```\n\n```{python}\ndef row_string_to_list(rs):\n    bucket = rs.split(\".\")[:-1]\n    for i in range(len(bucket)):\n        bucket[i] = int(bucket[i])\n    return bucket\n```\n\n```{python}\ndef x_sees_y(x, y):\n    n1, n2 = len(y), len(x)\n    if n2 < n1: return False\n    for i in range(n1-1):\n        if y[i] != x[i]: \n            return False\n    return y[n1-1] <= x[n1-1]\n```\n\nHere is where the more interesting part of the code begins, as it implements a lot of the concepts of argument validity.  Note that, if you'd like to see the details, the function above `x_sees_y`, could be interesting too.  It determines, for some two row numbers, whether one is allowed to \"see\" the other.  If `y` is in a subproof closed off from `x`, then it returns `False`.  Also if `y` is further along in the proof than `x`, it returns `False`.  But if `y` is supposed to be accessible from `x`, then it returns `True`.  \n\n```{python}\n### INTERESTING CODE ###\ndef validate(argument):\n    # Preprocess the argument into a list of lists.  \n    rl = rows_list(argument)\n    for i in range(len(rl)):\n        rl[i] = rl[i].split(\"; \")\n        rl[i][0] = row_string_to_list(rl[i][0])\n        rl[i][1] = shape(rl[i][1])\n    # When the preprocessing is done, the input \n    # \"(1.; P or Q; Premise), (2.; R or (P or Q); Disjunction Introduction, 1.)\" \n    # looks like \n    # [[[1], Disjunction(...), \"Premise\"], \\\n    #  [[2], Disjunction(...), \"Disjunction Introduction, 1.\"]]\n\n    # We will validate the row numbering of the argument, by \n    # building our own row numbering as we iterate through the \n    # list, and check that it matches the given numbering.\n    rownum = [1]\n    for i, row in enumerate(rl):\n        \n        if rownum != row[0]:\n            raise Exception(\"Invalid row numbering.\")\n        \n        reason = row[2].split(\", \")\n        reason_name = reason[0]\n        incr_rownum(rownum, reason_name)\n\n        if reason_name in [\"Premise\", \"Assumption\", \"End Subproof\"]: \n            continue\n\n        # Validating *Disjunction Elimination* requires \n        if reason_name == \"Disjunction Elimination\":\n            # finding the referenced row numbers\n            sup_ind1 = row_string_to_list(reason[1]) \n            sup_ind2 = row_string_to_list(reason[2])\n\n            # checking that they're not in a closed \n            # subproof\n            if not (x_sees_y(row[0],sup_ind1) and \\\n                    x_sees_y(row[0],sup_ind2)):\n                return False\n            \n            # getting the row at these numbers\n            for r in rl:\n                if r[0] == sup_ind1:\n                    sup1 = r[1]\n                if r[0] == sup_ind2:\n                    sup2 = r[1]\n            \n            # and checking that they match the pattern.\n            if not disjunction_elimination(sup1,sup2,row[1]):\n                return False\n        \n        if reason_name == \"Conditional Introduction\":\n            cond_prop = row[1]\n            next_row = rl[i+1]\n            if type(cond_prop) != Conditional:\n                return False\n            # Conditional introduction checks the next row to see\n            # that it's the beginning of an assumption with the \n            # same proposition as is the antecedent of the \n            # conditional.\n            cert = next_row[2] == \"Assumption\"\n            cert *= cond_prop.ante == next_row[1]\n            if not cert: return False\n            # Then it finds the closing \"End Subproof\", and checks\n            # that on the line before, the subproof ended at the \n            # consequent of the conditional.\n            cert = False\n            for j in range(i+1,len(rl)):\n                if len(rl[j][0]) == len(next_row[0]) \\\n                    and rl[j][2] == \"End Subproof\" \\\n                    and rl[j-1][1] == row[1].conseq:\n                    cert = True\n            if not cert: return cert\n        \n        return True\n\n        \n# disj_argument = \"(1.; P or Q; Premise), (2.; not Q; Premise), (3.; P; Disjunction Elimination, 1., 2.)\"\n# print(validate(disj_argument))\n\n# cond_argument = \"(1.; if P then Q; Conditional Introduction), (1.1.; P; Assumption), (1.2.; Q; Premise), (1.3.; ; End Subproof))\"\n# print(validate(cond_argument))\n        \n\n```\n\n::: {.callout-important title=\"Full Proof Assistant\" appearance=\"minimal\"}\nImplement the remaining inference rules and use them to extend the proof checker.\n:::"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"arrow","css":["../styles.css"],"toc":true,"output-file":"deduction.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.268","editor_options":{"chunk_output_type":"inline"},"jupyter":"python3","monobackgroundcolor":"#f9f9f9","code-block-border-left":"#31BAE9","theme":"cosmo","toc-expand":3,"title":"Deduction"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}